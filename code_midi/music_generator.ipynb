{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_midicsv as pm  # Documentation at https://github.com/timwedde/py_midicsv\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "# from midi2audio import FluidSynth\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from midi_tree_transform import MidiTreeTransform\n",
    "import os\n",
    "from keys_and_times import GetKeys, GetTimes, KeyFilter, TimeFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-906409973dda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msong\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMidiTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnote_digits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspeed_digits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msong\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_midi_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"piano_sonata_309_(hisamori).mid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"piano_sonata_310_1_(c)oguri.mid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"piano_sonata_457_(hisamori).mid\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnumber_of_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\acme_group\\vol3_semester2\\midi_transform.py\u001b[0m in \u001b[0;36mread_midi_file\u001b[1;34m(self, files)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mtime_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspeeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0mmaster_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_master_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspeeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;31m# TO DO: find out what we did to get notes and speeds arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\acme_group\\vol3_semester2\\midi_transform.py\u001b[0m in \u001b[0;36mgenerate_master_array\u001b[1;34m(self, time_steps, notes, speeds)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                 \u001b[0mj\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspeeds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "song_list = os.listdir('Study_Music')\n",
    "\n",
    "transformer = MidiTreeTransform()\n",
    "states, notes, lengths = transformer.read_midi_files(song_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_filter = TimeFilter(transformer)\n",
    "compressed_notes = time_filter.note_compress(notes)\n",
    "compressed_states = transformer.create_state_array(compressed_notes)\n",
    "\n",
    "key_class = GetKeys()\n",
    "key_name = key_class.random_key(song_list)\n",
    "sample_key = key_class.get_notes_from_key(key_name) \n",
    "\n",
    "key_filter = KeyFilter(key, transformer)\n",
    "states, notes = key_filter.filter(compressed_states, compressed_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = GetTimes()\n",
    "song_length = times.get_sample_length(song_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, n_jobs=-1, verbose=True, min_samples_split=100)\n",
    "rf.fit(states, notes)\n",
    "\n",
    "curr_state = np.zeros(states.shape[1], dtype=int)\n",
    "\n",
    "generated_notes = []\n",
    "for i in tqdm(range(song_length)):\n",
    "    p = rf.predict_proba(curr_state.reshape(1,-1))\n",
    "    p = p[0]\n",
    "\n",
    "    # Throttle the probability of nothing\n",
    "    p[0] *= .8\n",
    "    the_rest = p[1:]\n",
    "\n",
    "    rem_prop = 1. - p[0]\n",
    "    scale_fact = rem_prop/np.sum(the_rest)\n",
    "\n",
    "    p[1:] *= scale_fact\n",
    "\n",
    "    gen_note = np.random.choice(key_filter.filtered_dict_length, p=p)\n",
    "            \n",
    "    generated_notes.append(gen_note)\n",
    "    \n",
    "    curr_state = key_filter.update_state_array(curr_state, gen_note)\n",
    "\n",
    "generated_notes = np.array(generated_notes)\n",
    "\n",
    "generated_notes = key_filter.sift(generated_notes)\n",
    "generated_notes = time_filter.enjoy_the_silence(generated_notes)\n",
    "generated_notes\n",
    "\n",
    "transformer.save_as_midi(generated_notes, \"final_forest_song.midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -694426.2221             +nan\n",
      "         2      -52697.6352     +641728.5869\n",
      "         3      -52694.8907          +2.7445\n",
      "         4      -52691.3552          +3.5354\n",
      "         5      -52686.3831          +4.9721\n",
      "         6      -52678.6040          +7.7791\n",
      "         7      -52664.9149         +13.6891\n",
      "         8      -52639.4197         +25.4952\n",
      "         9      -52598.9474         +40.4723\n",
      "        10      -52552.3653         +46.5821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialHMM(n_components=20,\n",
       "               random_state=RandomState(MT19937) at 0x2932D36C8C8,\n",
       "               verbose=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes = hmm.MultinomialHMM(n_components=20, n_iter=100, tol=0.01, verbose=True)\n",
    "notes.fit(notes.reshape(-1, 1), lengths=lengths)\n",
    "\n",
    "new_notes = notes.sample(song_length)\n",
    "\n",
    "generated_notes = np.array(new_notes)\n",
    "\n",
    "generated_notes = key_filter.sift(generated_notes)\n",
    "generated_notes = time_filter.enjoy_the_silence(generated_notes)\n",
    "generated_notes\n",
    "\n",
    "transformer.save_as_midi(generated_notes, \"final_hmm_song.midi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
